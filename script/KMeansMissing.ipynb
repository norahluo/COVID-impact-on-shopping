{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kmeans_missing(object):\n",
    "    def __init__(self, potential_centroids, n_clusters):\n",
    "        #initialize with potential centroids\n",
    "        self.n_clusters = n_clusters\n",
    "        self.potential_centroids = potential_centroids\n",
    "        \n",
    "    def fit(self, data, max_iter=10, number_of_runs = 1, init = 'random'):\n",
    "        data = data.to_numpy()\n",
    "        n_clusters = self.n_clusters\n",
    "        potential_centroids = self.potential_centroids\n",
    "        dist_mat = np.zeros((data.shape[0], n_clusters))\n",
    "        all_centroids = np.zeros((n_clusters, data.shape[1], number_of_runs))\n",
    "        costs = np.zeros((number_of_runs,))\n",
    "        labels = np.zeros((number_of_runs, data.shape[0]))\n",
    "        \n",
    "        for k in range(number_of_runs):\n",
    "            \n",
    "        #####################################################################################################\n",
    "        ####################################### Initialization Method #######################################\n",
    "            if init == 'random':\n",
    "                idx = np.random.choice(range(potential_centroids.shape[0]), size = (n_clusters), replace=False)\n",
    "                centroids = potential_centroids[idx]\n",
    "                \n",
    "            elif init == 'kmeans++':\n",
    "                candidate = potential_centroids\n",
    "                centroids = np.zeros((n_clusters, candidate.shape[1]))\n",
    "                # initialize the first centroid randomly\n",
    "                idx = np.random.choice(range(candidate.shape[0]))\n",
    "                centroids[0] = candidate[idx]\n",
    "                # once selected, no longer be candidate for centroids\n",
    "                candidate = np.delete(candidate, idx, 0)\n",
    "               \n",
    "                dist_ = np.zeros((candidate.shape[0], len(centroids)-1))\n",
    "                # find the other centroids\n",
    "                for j in range(1, n_clusters):                   \n",
    "                    # calculate the distance of candidate to each centroid\n",
    "                    dist_[:,j-1] = np.sum((candidate - centroids[j-1])**2, axis = 1)\n",
    "                    \n",
    "                    # distance between point and the nearest center\n",
    "                    min_dist = np.min(dist_[:,:j], axis = 1)\n",
    "                    # probability distribution\n",
    "                    prob = min_dist/sum(min_dist)\n",
    "                    idx = np.random.choice(range(len(prob)), size = 1, p = prob)\n",
    "                    \n",
    "                    # update centroids and delete it from candidate\n",
    "                    centroids[j] = candidate[idx]\n",
    "                    candidate = np.delete(candidate, idx, 0)\n",
    "                    dist_ = np.delete(dist_, idx, 0)\n",
    "                    \n",
    "         ################################################################################################### \n",
    "         ###################################################################################################\n",
    "            \n",
    "            clusters = np.zeros((data.shape[0],))\n",
    "            old_clusters = np.zeros(data.shape[0])\n",
    "            \n",
    "            \n",
    "            for i in range(max_iter):\n",
    "                # Step 1: calculate distance to centroids\n",
    "                for j in range(n_clusters):\n",
    "                    # for records with nan, the distance will be calculated using only features with valid value.\n",
    "                    dist_mat[:,j] = np.nansum((centroids[j]-data)**2, axis = 1)\n",
    "                    \n",
    "                # Step 2: Assign to clusters\n",
    "                clusters = np.argmin(dist_mat, axis = 1)\n",
    "                \n",
    "                # Step 3: Update clusters centroids\n",
    "                for j in range(n_clusters):\n",
    "                    centroids[j] = np.nanmean(data[clusters == j], axis = 0)\n",
    "                \n",
    "                # When # of identified clusters < n_clusters, reset centroids\n",
    "                if np.isnan(centroids).any():\n",
    "                    centorids = potential_centroids[idx]\n",
    "                    \n",
    "                if all(np.equal(clusters, old_clusters)):\n",
    "                    break\n",
    "                    \n",
    "                if i == max_iter - 1:\n",
    "                    print('no convergence before maximun iteration')\n",
    "                    # Avoid the case that put all records in one cluster\n",
    "                    centroids = potential_centroids[idx]\n",
    "                    for j in range(n_clusters):\n",
    "                        dist_mat[:,j] = np.nansum((data - centroids[j])**2, axis = 1)\n",
    "                else:\n",
    "                    clusters, old_clusters = old_clusters, clusters # seems not necessary to assign old_clusters to clusters\n",
    "            \n",
    "            all_centroids[:,:,k] = centroids\n",
    "            costs[k] = np.mean(np.min(dist_mat, axis = 1))\n",
    "            labels[k] = np.argmin(dist_mat, axis = 1)\n",
    "            \n",
    "        self.costs = costs\n",
    "        self.costs = np.min(costs)\n",
    "        self.best_model = np.argmin(costs)\n",
    "        self.centroids = all_centroids[:,:, self.best_model]\n",
    "        self.all_centroids = all_centroids\n",
    "        self.labels = labels[self.best_model]\n",
    "    \n",
    "    def silhouette(self, data):\n",
    "        data = data.to_numpy()\n",
    "        n_clusters = self.n_clusters\n",
    "        centroids = self.centroids\n",
    "        dist_mat = np.zeros((data.shape[0], n_clusters))\n",
    "        sil_ = []\n",
    "        for k in range(n_clusters):\n",
    "            dist_mat[:,k] = np.nansum((data - centroids[k])**2, axis = 1)\n",
    "        center = np.argmin(dist_mat, axis = 1)\n",
    "        nearest_center = np.argsort(dist_mat, axis = 1)[:,1]\n",
    "        for i in range(len(data)):\n",
    "            a = np.mean([np.nansum((data[i] - data[j])**2)**0.5  for j in range(len(center)) if (center[j]==center[i]) & (i != j)])\n",
    "            b = np.mean([np.nansum((data[i] - data[j])**2)**0.5  for j in range(len(center)) if (center[j]==nearest_center[i])])\n",
    "            sil_.append((b - a)/max(a,b))\n",
    "        return np.nanmean(sil_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
